{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7cc4a89b-f7e3-4cee-8d57-85b286556aa5",
    "_uuid": "42f5b143-a902-4491-9069-16b04640da38",
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "bb8d6efc-a60b-4edd-b442-b71ea221f62f",
    "_uuid": "40010185-98f2-4411-8b33-11444ce3071e",
    "id": "sCV30xyVhFbE"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "589bc6fa-eaaa-462e-a264-da7bb4151566",
    "_uuid": "f7eb92cd-7a85-4787-ab20-ff68d37ad590",
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['NORMAL', 'PNEUMONIA']\n",
    "def read_images(directory):\n",
    "    x = []\n",
    "    y = []\n",
    "    for label in labels: \n",
    "        path = os.path.join(directory, label)\n",
    "        image_class = labels.index(label)\n",
    "        for image_name in os.listdir(path):\n",
    "            if image_name == \".DS_Store\":\n",
    "                continue\n",
    "            image = cv2.imread(os.path.join(path, image_name), cv2.IMREAD_GRAYSCALE)\n",
    "            image = cv2.resize(image, (150, 150))\n",
    "            x.append(image / 255)\n",
    "            y.append(image_class)\n",
    "    return ((np.array(x)).reshape(-1, 150, 150, 1), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m read_images(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m x_val, y_val \u001b[38;5;241m=\u001b[39m read_images(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./val\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_images' is not defined"
     ]
    }
   ],
   "source": [
    "x_test, y_test = read_images('./test')\n",
    "x_val, y_val = read_images('./val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate batches of augmented data using the ImageDataGenerator Class\n",
    "Data augmentation is a technique used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data. It acts as a regularizer and helps reduce overfitting when training our model. Some popular augmentations people use are grayscales, horizontal flips, random crops, color jitters, translations, rotations, and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 10,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2)\n",
    "training_set = train_datagen.flow_from_directory('../input/chest-xray-pneumonia/chest_xray/train/',\n",
    "                                                 target_size = (150, 150),\n",
    "                                                 batch_size = 32,\n",
    "                                                 color_mode = 'grayscale',\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('../input/chest-xray-pneumonia/chest_xray/test/',\n",
    "                                            target_size = (150, 150),\n",
    "                                            batch_size = 32,\n",
    "                                            color_mode = 'grayscale',\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "05e3e71d-938f-4898-aeb7-dc7c5d1125a5",
    "_uuid": "e5a6e653-c467-4f85-afbd-a8e0efa536a8",
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Building the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "86e59e3e-db1f-4308-abcf-bfbf256eecd4",
    "_uuid": "d28fcb90-8e7c-46a8-8b66-a49a9b7a3ae0",
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b3a56e5c-b88c-4949-86ba-bba9dc614385",
    "_uuid": "12302c57-db95-4f8d-ad82-81a703a40c60",
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "71857473-746f-4368-9699-146860740408",
    "_uuid": "c8b002f1-cc34-4fd2-9c2b-7ed03c6b0c77",
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### First convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ce81b225-ce68-420d-a8b5-5e69a6811b79",
    "_uuid": "10c49a88-7981-4e39-865a-de02b9ec21fb",
    "id": "XPzPrMckl-hV"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[150, 150, 1]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8f5d5568-d553-4dea-a5bf-8cd9e3cf1c1a",
    "_uuid": "6f5c0310-c15f-4fbb-985f-15c7f24c9564",
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Second convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3eee1f48-1099-4059-9c03-ddb86b996b4c",
    "_uuid": "405aba6b-0ff6-4759-b3e8-f3505256e7ae",
    "id": "i_-FZjn_m8gk"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b66f3bb3-812d-4213-b40b-15ee9e15b8b4",
    "_uuid": "1513cdda-9f58-495f-b26b-153729e3d994",
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b34aaa51-ba15-4a6c-935d-24e928e3f490",
    "_uuid": "8273b35a-390c-4279-9628-689e2a4f8e1c",
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Connection\n",
    "#### We will use the Dropout technique which works by randomly reducing the number of interconnecting neurons within a neural network. At every training step, each neuron has a chance of being left out, or rather, dropped out of the collated contribution from connected neurons. This technique minimizes overfitting because each neuron becomes independently sufficient, in the sense that the neurons within the layers learn weight values that are not based on the cooperation of its neighbouring neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4eca0afe-391e-4c13-b3a5-a58df1c15b44",
    "_uuid": "f3ef20d4-9024-47e5-a4ff-31e7a2bcecea",
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "373be719-1c1b-4fce-9403-36f9e5b9dafa",
    "_uuid": "dd798b33-68db-49ec-ac34-98771dc8ffd7",
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5432ba72-d0ca-4319-ad6d-dda2a2dfd763",
    "_uuid": "0fcbadc8-bea5-43e3-a4ed-a3796c341d01",
    "id": "1p_Zj1Mc3Ko_"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f0ef3a25-bac2-40dc-9ba0-e9a9fc98e8ee",
    "_uuid": "76bdb421-71e5-42d2-8e4d-292e70c01eb0",
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For our model we will use the Adam optimizer. The Adam optimization algorithm is an extension to stochastic gradient descent that has recently seen broader adoption for deep learning applications in computer vision. Stochastic gradient descent maintains a single learning rate (termed alpha) for all weight updates and the learning rate does not change during training. Using the Adam optimizier a learning rate is maintained for each network weight (parameter) and separately adapted as learning unfolds.\n",
    "#### Adam combines the advantages of two other extensions of stochastic gradient descent. Specifically:\n",
    "\n",
    "* Adaptive Gradient Algorithm (AdaGrad) that maintains a per-parameter learning rate that improves performance on problems with sparse gradients.\n",
    "* Root Mean Square Propagation (RMSProp) that also maintains per-parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight (e.g. how quickly it is changing). This means the algorithm does well on non-stationary problems like noisy images classification.  \n",
    "\n",
    "#### Adam optimizer realizes the benefits of both AdaGrad and RMSProp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e4da4945-f7a3-42cf-a6bf-a35ae8b7f462",
    "_uuid": "595dee30-e7ce-40d5-920b-5dc06ab6e1f1",
    "id": "NALksrNQpUlJ"
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bc6f7aa3-f292-4750-9e3e-a22ce01e29b4",
    "_uuid": "916f6cc8-8992-46c3-80bc-be32112fbc47",
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c3af03a2-a64d-4a5c-8608-532170f324af",
    "_uuid": "daeb08e6-ceb4-4c9b-a373-13311d27059b",
    "id": "XUj1W4PJptta"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.25,\n",
    "                              patience = 3, min_lr = 0.00001)\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 12, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.evaluate(x_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(x_test)\n",
    "y_pred = [1 if x > 0.5 else 0 for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = pd.DataFrame(cm , index = ['0','1'] , columns = ['0','1'])\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.heatmap(cm,cmap= \"Blues\", linewidth = 3 , annot = True, \n",
    "            fmt='',xticklabels = ['Pneumonia', 'Normal'],yticklabels = ['Pneumonia', 'Normal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9bf41f71-1834-45aa-8ada-9c4f79ab2d96",
    "_uuid": "8eb0db26-b504-4c99-b760-59abdf1a65e6",
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6fc89da4-0735-4883-b19c-8cc08d019e8a",
    "_uuid": "57f7f110-061b-477a-8fde-32e1f66ce9f1",
    "id": "gsSiWEJY1BPB"
   },
   "outputs": [],
   "source": [
    "test_image = image.load_img('../input/chest-xray-pneumonia/chest_xray/val/PNEUMONIA/person1946_bacteria_4875.jpeg',\n",
    "                            target_size = (150, 150), color_mode = 'grayscale')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "if result[0][0] == 1:\n",
    "  prediction = 'Pneumonia'\n",
    "else:\n",
    "  prediction = 'Normal'\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 17810,
     "sourceId": 23812,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30019,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
